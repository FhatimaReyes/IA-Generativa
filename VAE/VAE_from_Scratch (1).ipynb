{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sUd2xYl_Vmoe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from keras.layers import Lambda\n",
        "\n",
        "input_dim=784\n",
        "intermediate_dim=200\n",
        "latent_dim=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLQ7H695DI8l"
      },
      "source": [
        "**Activation Classes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "KB1FLI7sDHdZ"
      },
      "outputs": [],
      "source": [
        "class Activation_ReLU:\n",
        "  def __init__(self):\n",
        "    self.input=[]\n",
        "    self.output=[]\n",
        "    self.dinputs=[]\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.input = input\n",
        "    self.output=np.maximum(0, input)\n",
        "\n",
        "  def backward(self, dvalues):\n",
        "    dvalues = np.sum(dvalues, axis=0, keepdims=True)\n",
        "    self.dinputs=dvalues*np.where(self.output > 0, 1, 0)\n",
        "\n",
        "class Activation_Sigmoid:\n",
        "  def __init__(self):\n",
        "    self.input=[]\n",
        "    self.output=[]\n",
        "    self.dinputs=[]\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.output = 1 / (1 + np.exp(-input))\n",
        "\n",
        "  def backward(self, dvalues):\n",
        "    self.dinputs = dvalues * (1 - self.output) * self.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xeP-PYr2xkTF"
      },
      "source": [
        "**Clase Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Ch-v9g0_x3Db"
      },
      "outputs": [],
      "source": [
        "class Encoder:\n",
        "\n",
        "  def __init__(self, input_dim, intermediate_dim, latent_dim):\n",
        "    self.layer1=Dense(input_dim, intermediate_dim)\n",
        "    self.layer1Activation=Activation_ReLU()\n",
        "    self.z_mu=Dense(intermediate_dim, latent_dim)\n",
        "    self.z_log_sigma2=Dense(intermediate_dim, latent_dim)\n",
        "    self.z=[]\n",
        "\n",
        "  def sample_z(self):\n",
        "    epsilon = np.random.normal(0, 1, size=self.z_mu.output.shape)\n",
        "    return self.z_mu.output + np.exp(self.z_log_sigma2.output*.5) * epsilon\n",
        "\n",
        "  def encode(self, input):\n",
        "    self.layer1.forward(input)\n",
        "    self.layer1Activation.forward(self.layer1.output)\n",
        "\n",
        "    self.z_mu.forward(self.layer1Activation.output)\n",
        "\n",
        "    self.z_log_sigma2.forward(self.layer1Activation.output)\n",
        "\n",
        "    self.z=self.sample_z();\n",
        "\n",
        "    return self.z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI5FIVoQxpR6"
      },
      "source": [
        "**Clase Decoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "66hYcXf8x3py"
      },
      "outputs": [],
      "source": [
        "class Decoder:\n",
        "  def __init__(self, latent_dim, intermediate_dim, input_dim):\n",
        "    self.layer1=Dense(latent_dim, intermediate_dim)\n",
        "    self.layer1Activation=Activation_ReLU()\n",
        "    self.layer2=Dense(intermediate_dim, input_dim)\n",
        "    self.layer2Activation=Activation_Sigmoid()\n",
        "\n",
        "  def decode(self, input):\n",
        "    self.layer1.forward(input)\n",
        "    self.layer1Activation.forward(self.layer1.output)\n",
        "\n",
        "\n",
        "    self.layer2.forward(self.layer1Activation.output)\n",
        "    self.layer2Activation.forward(self.layer2.output)\n",
        "\n",
        "    return self.layer2Activation.output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWDrWDJUxsJL"
      },
      "source": [
        "**Clase Dense**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Y3qKXVzxx4W9"
      },
      "outputs": [],
      "source": [
        "class Dense:\n",
        "  def __init__(self, input_dim, neurons, weight_regularizer_l1=[0],\n",
        "               weight_regularizer_l2=[0], bias_regularizer_l1=[0], bias_regularizer_l2=[0]):\n",
        "\n",
        "    self.weights=0.1*np.random.randn(input_dim, neurons)\n",
        "    self.biases=np.zeros((1, neurons))\n",
        "    self.input=[]\n",
        "    self.output=[]\n",
        "    self.weight_regularizer_l1=np.array(weight_regularizer_l1)\n",
        "    self.weight_regularizer_l2=np.array(weight_regularizer_l2)\n",
        "    self.bias_regularizer_l1=np.array(bias_regularizer_l1)\n",
        "    self.bias_regularizer_l2=np.array(bias_regularizer_l2)\n",
        "    self.dweights=0\n",
        "    self.dbiases=0\n",
        "    self.dinputs=0\n",
        "\n",
        "  def  forward(self, input):\n",
        "    self.input=input\n",
        "    self.output=np.dot(self.input, self.weights)+self.biases\n",
        "\n",
        "  def backward(self, dvalues):\n",
        "    self.dweights = np.dot(self.input.T, dvalues)\n",
        "    self.dbiases = np.sum(dvalues, axis=0, keepdims=True)\n",
        "\n",
        "    if self.weight_regularizer_l1.any()>0:\n",
        "      dL1=np.ones_like(self.weights)\n",
        "      dL1[self.weights<0]=-1\n",
        "      self.dweights += np.squeeze(self.weight_regularizer_l1 * dL1, axis=0)\n",
        "\n",
        "    if self.weight_regularizer_l2.any()>0:\n",
        "      self.dweights += 2 * np.squeeze(self.weight_regularizer_l2 * \\\n",
        "                       self.weights, axis=0)\n",
        "\n",
        "    if self.bias_regularizer_l1.any() > 0:\n",
        "      dL1 = np.ones_like(self.biases)\n",
        "      dL1[self.biases < 0] = -1\n",
        "      self.dbiases += self.bias_regularizer_l1 * dL1\n",
        "\n",
        "    if self.bias_regularizer_l2.any() > 0:\n",
        "      self.dbiases += 2 * self.bias_regularizer_l2 * \\\n",
        "                      self.biases\n",
        "\n",
        "    self.dinputs = np.dot(dvalues, self.weights.T)\n",
        "\n",
        "  def backward2(self, dvalues):\n",
        "      self.dbiases=dvalues\n",
        "      if self.input.shape[0]!=1:\n",
        "         self.input=self.input.reshape(1, -1)\n",
        "      self.dweights=np.dot(self.input.T,dvalues)\n",
        "      self.dinputs=np.dot(dvalues, self.weights.T)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPeViZmLxu1a"
      },
      "source": [
        "**Perdidas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "msH3jD13x5Qb"
      },
      "outputs": [],
      "source": [
        "class Loss:\n",
        "  def __init__(self):\n",
        "    self.accumulated_sum=0\n",
        "    self.accumulated_count=0\n",
        "\n",
        "  def regularization_loss(self):\n",
        "    regularization_loss = 0\n",
        "    count=1\n",
        "    for layer in self.trainable_layers:\n",
        "      print(count)\n",
        "      count+=1\n",
        "      if layer.weight_regularizer_l1.any()>0:\n",
        "        print(\"wrl1: \", layer.weight_regularizer_l1.shape)\n",
        "        print(\"w: \", layer.weights.shape)\n",
        "        regularization_loss += layer.weight_regularizer_l1 * \\\n",
        "                              np.sum(np.abs(layer.weights))\n",
        "        print(\"rl: \", regularization_loss.shape)\n",
        "      if layer.weight_regularizer_l2.any() > 0:\n",
        "        regularization_loss += layer.weight_regularizer_l2 * \\\n",
        "                              np.sum(layer.weights * \\\n",
        "                                      layer.weights)\n",
        "\n",
        "      if layer.bias_regularizer_l1.any() > 0:\n",
        "        regularization_loss += layer.bias_regularizer_l1 * \\\n",
        "                              np.sum(np.abs(layer.biases))\n",
        "\n",
        "      if layer.bias_regularizer_l2.any() > 0:\n",
        "        regularization_loss += layer.bias_regularizer_l2 * \\\n",
        "                              np.sum(layer.biases * \\\n",
        "                                      layer.biases)\n",
        "    return regularization_loss\n",
        "\n",
        "  def remember_trainable_layers(self, trainable_layers):\n",
        "    self.trainable_layers=trainable_layers\n",
        "\n",
        "  def calculate(self, output, y, *, include_regularization = False):\n",
        "    sample_losses=self.forward(output, y)\n",
        "    data_loss = np.mean(sample_losses)\n",
        "\n",
        "    self.accumulated_sum += np.sum(sample_losses)\n",
        "    self.accumulated_count += len(sample_losses)\n",
        "\n",
        "    if not include_regularization:\n",
        "      return data_loss\n",
        "    else:\n",
        "      return data_loss, self.regularization_loss()\n",
        "\n",
        "  def calculate_accumulated(self, *, include_regularization = False):\n",
        "    data_loss = self.accumulated_sum / self.accumulated_count\n",
        "\n",
        "    if not include_regularization:\n",
        "      return data_loss\n",
        "    else:\n",
        "      return data_loss, self.regularization_loss()\n",
        "\n",
        "  def new_pass(self):\n",
        "    self.accumulated_sum = 0\n",
        "    self.accumulated_count = 0\n",
        "\n",
        "class LossBinaryCrossEntropy(Loss):\n",
        "  def forward(self, y_pred, y_true):\n",
        "    y_pred_clipped = np.clip(y_pred, 1e-7, 1 - 1e-7)\n",
        "\n",
        "    sample_losses = -(y_true * np.log(y_pred_clipped) + (1 - y_true) * np.log(1 - y_pred_clipped))\n",
        "    sample_losses = np.mean(sample_losses, axis=1)\n",
        "\n",
        "    return sample_losses\n",
        "\n",
        "  def backward(self, dvalues, y_true):\n",
        "    samples = len(dvalues)\n",
        "    outputs = len(dvalues[0])\n",
        "\n",
        "    clipped_dvalues = np.clip(dvalues, 1e-7, 1 - 1e-7)\n",
        "\n",
        "    self.dinputs = -(y_true / clipped_dvalues - (1 - y_true)\n",
        "                     /(1 - clipped_dvalues))/outputs\n",
        "\n",
        "    self.dinputs = self.dinputs / samples\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UoJchqXiJO1I"
      },
      "source": [
        "**Optimizador rmsprop**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "cY0k86fuJONm"
      },
      "outputs": [],
      "source": [
        "class Rmsprop:\n",
        "  def __init__(self, learning_rate=0.001, decay=0.01, epsilon=1e-8, rho=0.9):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.current_learning_rate = learning_rate\n",
        "    self.decay = decay\n",
        "    self.iterations = 0\n",
        "    self.epsilon = epsilon\n",
        "    self.rho = rho\n",
        "\n",
        "  def pre_update_params(self):\n",
        "    if self.decay:\n",
        "      self.current_learning_rate = self.learning_rate * \\\n",
        "          (1. / (1. + self.decay * self.iterations))\n",
        "\n",
        "  def update_params(self, layer):\n",
        "    if not hasattr(layer, 'wight_cache'):\n",
        "      layer.weight_cache = np.zeros_like(layer.weights)\n",
        "      layer.bias_cache = np.zeros_like(layer.biases)\n",
        "\n",
        "    layer.weight_cache = self.rho * layer.weight_cache + \\\n",
        "        (1 - self.rho) * layer.dweights**2\n",
        "    layer.bias_cache = self.rho * layer.bias_cache + \\\n",
        "        (1 - self.rho) * layer.dbiases**2\n",
        "\n",
        "    layer.weights += -self.current_learning_rate * \\\n",
        "                    layer.dweights / \\\n",
        "                    (np.sqrt(layer.weight_cache) + self.epsilon)\n",
        "    layer.biases += -self.current_learning_rate * \\\n",
        "                    layer.dbiases / \\\n",
        "                    (np.sqrt(layer.bias_cache) + self.epsilon)\n",
        "    return layer\n",
        "\n",
        "  def post_update_params(self):\n",
        "    self.iterations += 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93GCACVFx5yy"
      },
      "source": [
        "**Importación del Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZsRni4MtYb6V"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test  = x_test.astype( 'float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test  = x_test.reshape( (len(x_test),  np.prod(x_test.shape[1:])))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_test=[x_test[3], x_test[15], x_test[6]]"
      ],
      "metadata": {
        "id": "UAM8InsMHxkq"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hosvwAOdxcY1"
      },
      "source": [
        "**Clase VAE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "ekoWgy52x2WQ"
      },
      "outputs": [],
      "source": [
        "class VAE:\n",
        "  def __init__(self, input_dim, intermediate_dim, latent_dim):\n",
        "    self.encoder=Encoder(input_dim, intermediate_dim, latent_dim)\n",
        "    self.decoder=Decoder(latent_dim, intermediate_dim, input_dim)\n",
        "    self.optimizer=Rmsprop()\n",
        "    self.binaryCrossEntropy=LossBinaryCrossEntropy()\n",
        "    self.trainable_layers=[self.encoder.layer1, self.encoder.z_mu, self.encoder.z_log_sigma2,\\\n",
        "                        self.decoder.layer1, self.decoder.layer2]\n",
        "\n",
        "    self.binaryCrossEntropy.remember_trainable_layers(self.trainable_layers)\n",
        "\n",
        "\n",
        "  def predict(self, input):\n",
        "    return self.decoder.decode(self.encoder.encode(input))\n",
        "\n",
        "  #Funcio de perdida ELBO\n",
        "  def ELBO(self, input, output):\n",
        "      logP = len(input)*self.binaryCrossEntropy.forward(output, input)\n",
        "    #D(Q(z|x)||P(z))\n",
        "      Dk1 = 0.5 * np.sum(np.exp(self.encoder.z_log_sigma2.output)+np.square(self.encoder.z_mu.output)-1. - self.encoder.z_log_sigma2.output, axis=-1)\n",
        "      logP=np.mean(logP)\n",
        "      return np.mean(logP+Dk1)\n",
        "\n",
        "\n",
        "  def backward(self, input, output):\n",
        "    loss=output-input\n",
        "    self.decoder.layer2Activation.backward(loss)\n",
        "    self.decoder.layer2.backward2(self.decoder.layer2Activation.dinputs)\n",
        "    self.decoder.layer1Activation.backward(self.decoder.layer2.dinputs)\n",
        "    self.decoder.layer1.backward2(self.decoder.layer1Activation.dinputs)\n",
        "    self.encoder.z_log_sigma2.backward2(self.decoder.layer1.dinputs)\n",
        "    self.encoder.z_mu.backward2(self.decoder.layer1.dinputs)\n",
        "    self.encoder.layer1Activation.backward(self.encoder.z_mu.dinputs)\n",
        "    self.encoder.layer1.backward2(self.encoder.layer1Activation.dinputs)\n",
        "\n",
        "\n",
        "  def fit(self, input, epochs=1, batch_size=None, validation_data=None):\n",
        "    for epoch in range(1, epochs+1):\n",
        "      print(\"Epoch: \", epoch)\n",
        "      loss=0\n",
        "      self.binaryCrossEntropy.new_pass()\n",
        "      for data in input:\n",
        "        output=self.predict(data)\n",
        "        loss += self.ELBO(data, output)\n",
        "        self.backward(data, output)\n",
        "        self.optimizer.pre_update_params()\n",
        "        for layer in self.trainable_layers:\n",
        "          layer=self.optimizer.update_params(layer)\n",
        "        self.optimizer.post_update_params()\n",
        "      print(\"Loss: \", loss/len(input))\n",
        "    print(\"train end\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcGzq3jex_lp"
      },
      "source": [
        "**Pruebas durante realización**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNSHa41ceUY4",
        "outputId": "3b5c149c-2d41-4504-c411-430575527a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1\n",
            "Loss:  537.8785650593428\n",
            "Epoch:  2\n",
            "Loss:  459.36338225523474\n",
            "Epoch:  3\n",
            "Loss:  355.00359312299844\n",
            "Epoch:  4\n",
            "Loss:  322.67900393080106\n",
            "Epoch:  5\n",
            "Loss:  281.8495985323041\n",
            "Epoch:  6\n",
            "Loss:  252.8128306341721\n",
            "Epoch:  7\n",
            "Loss:  230.32444248022458\n",
            "Epoch:  8\n",
            "Loss:  224.46234599058047\n",
            "Epoch:  9\n",
            "Loss:  213.90581999438754\n",
            "Epoch:  10\n",
            "Loss:  218.8036212739377\n",
            "Epoch:  11\n",
            "Loss:  209.0098771281786\n",
            "Epoch:  12\n",
            "Loss:  202.3508376335598\n",
            "Epoch:  13\n",
            "Loss:  185.60505171870776\n",
            "Epoch:  14\n",
            "Loss:  195.15493025747597\n",
            "Epoch:  15\n",
            "Loss:  177.45293632526503\n",
            "Epoch:  16\n",
            "Loss:  206.22748733936373\n",
            "Epoch:  17\n",
            "Loss:  169.99926056464355\n",
            "Epoch:  18\n",
            "Loss:  174.32090668069478\n",
            "Epoch:  19\n",
            "Loss:  181.19778553023977\n",
            "Epoch:  20\n",
            "Loss:  149.92786928382978\n",
            "Epoch:  21\n",
            "Loss:  176.02982882593463\n",
            "Epoch:  22\n",
            "Loss:  146.85149278466716\n",
            "Epoch:  23\n",
            "Loss:  202.8167570419641\n",
            "Epoch:  24\n",
            "Loss:  136.2724854497588\n",
            "Epoch:  25\n",
            "Loss:  152.10548007363067\n",
            "Epoch:  26\n",
            "Loss:  136.3769391315839\n",
            "Epoch:  27\n",
            "Loss:  136.34260675670234\n",
            "Epoch:  28\n",
            "Loss:  176.2965821935438\n",
            "Epoch:  29\n",
            "Loss:  127.84645210542028\n",
            "Epoch:  30\n",
            "Loss:  148.66892970021846\n",
            "Epoch:  31\n",
            "Loss:  130.15936241547413\n",
            "Epoch:  32\n",
            "Loss:  154.10276723375713\n",
            "Epoch:  33\n",
            "Loss:  128.16442302519633\n",
            "Epoch:  34\n",
            "Loss:  121.46788684111561\n",
            "Epoch:  35\n",
            "Loss:  126.67484416319076\n",
            "Epoch:  36\n",
            "Loss:  164.41376135697737\n",
            "Epoch:  37\n",
            "Loss:  124.18959195312972\n",
            "Epoch:  38\n",
            "Loss:  178.0597730915946\n",
            "Epoch:  39\n",
            "Loss:  136.9425162806563\n",
            "Epoch:  40\n",
            "Loss:  162.76997811881242\n",
            "Epoch:  41\n",
            "Loss:  130.89005389199227\n",
            "Epoch:  42\n",
            "Loss:  167.37912452635223\n",
            "Epoch:  43\n",
            "Loss:  145.77752584777306\n",
            "Epoch:  44\n",
            "Loss:  135.20319237133833\n",
            "Epoch:  45\n",
            "Loss:  130.68050571435646\n",
            "Epoch:  46\n",
            "Loss:  133.83248519769037\n",
            "Epoch:  47\n",
            "Loss:  138.88955547080022\n",
            "Epoch:  48\n",
            "Loss:  160.15569142534778\n",
            "Epoch:  49\n",
            "Loss:  131.68837460314657\n",
            "Epoch:  50\n",
            "Loss:  125.28442120445602\n",
            "Epoch:  51\n",
            "Loss:  138.82453079557163\n",
            "Epoch:  52\n",
            "Loss:  143.1931527479666\n",
            "Epoch:  53\n",
            "Loss:  153.70600019739513\n",
            "Epoch:  54\n",
            "Loss:  128.87878885650744\n",
            "Epoch:  55\n",
            "Loss:  137.3573508865262\n",
            "Epoch:  56\n",
            "Loss:  123.43495645901824\n",
            "Epoch:  57\n",
            "Loss:  123.03356155785929\n",
            "Epoch:  58\n",
            "Loss:  125.62257143211532\n",
            "Epoch:  59\n",
            "Loss:  147.72515719493586\n",
            "Epoch:  60\n",
            "Loss:  124.17680774542957\n",
            "Epoch:  61\n",
            "Loss:  127.55519939710922\n",
            "Epoch:  62\n",
            "Loss:  123.15374795454021\n",
            "Epoch:  63\n",
            "Loss:  122.86682641049454\n",
            "Epoch:  64\n",
            "Loss:  117.19501671502395\n",
            "Epoch:  65\n",
            "Loss:  120.18211463197561\n",
            "Epoch:  66\n",
            "Loss:  124.60361032801757\n",
            "Epoch:  67\n",
            "Loss:  174.9675249479677\n",
            "Epoch:  68\n",
            "Loss:  126.94312220683834\n",
            "Epoch:  69\n",
            "Loss:  120.38258639009244\n",
            "Epoch:  70\n",
            "Loss:  135.8012969221098\n",
            "Epoch:  71\n",
            "Loss:  124.7827682130694\n",
            "Epoch:  72\n",
            "Loss:  129.19630103313145\n",
            "Epoch:  73\n",
            "Loss:  121.91133607129304\n",
            "Epoch:  74\n",
            "Loss:  121.49988455256334\n",
            "Epoch:  75\n",
            "Loss:  125.51651379839761\n",
            "Epoch:  76\n",
            "Loss:  121.29683140357575\n",
            "Epoch:  77\n",
            "Loss:  125.56821896677859\n",
            "Epoch:  78\n",
            "Loss:  120.93370983456892\n",
            "Epoch:  79\n",
            "Loss:  162.18497223138888\n",
            "Epoch:  80\n",
            "Loss:  169.01849798337093\n",
            "Epoch:  81\n",
            "Loss:  128.50165269817433\n",
            "Epoch:  82\n",
            "Loss:  130.24303674531362\n",
            "Epoch:  83\n",
            "Loss:  124.76711795470773\n",
            "Epoch:  84\n",
            "Loss:  150.60185137636162\n",
            "Epoch:  85\n",
            "Loss:  131.4354584429631\n",
            "Epoch:  86\n",
            "Loss:  154.89406203140433\n",
            "Epoch:  87\n",
            "Loss:  189.5475539518725\n",
            "Epoch:  88\n",
            "Loss:  133.05901958479387\n",
            "Epoch:  89\n",
            "Loss:  175.07229083731053\n",
            "Epoch:  90\n",
            "Loss:  135.11658810915708\n",
            "Epoch:  91\n",
            "Loss:  130.25765441417983\n",
            "Epoch:  92\n",
            "Loss:  126.2302178941997\n",
            "Epoch:  93\n",
            "Loss:  136.22071745712137\n",
            "Epoch:  94\n",
            "Loss:  131.59074052289034\n",
            "Epoch:  95\n",
            "Loss:  127.58281602977654\n",
            "Epoch:  96\n",
            "Loss:  124.94826575242588\n",
            "Epoch:  97\n",
            "Loss:  136.32278734603088\n",
            "Epoch:  98\n",
            "Loss:  158.25935847292354\n",
            "Epoch:  99\n",
            "Loss:  208.48681406140633\n",
            "Epoch:  100\n",
            "Loss:  127.29807747840782\n",
            "Epoch:  101\n",
            "Loss:  131.7168819246779\n",
            "Epoch:  102\n",
            "Loss:  131.6010624474959\n",
            "Epoch:  103\n",
            "Loss:  193.37880879564815\n",
            "Epoch:  104\n",
            "Loss:  132.40350116823726\n",
            "Epoch:  105\n",
            "Loss:  130.11401312958037\n",
            "Epoch:  106\n",
            "Loss:  137.93286873148338\n",
            "Epoch:  107\n",
            "Loss:  148.04224715635743\n",
            "Epoch:  108\n",
            "Loss:  138.71840334971532\n",
            "Epoch:  109\n",
            "Loss:  136.23052812310888\n",
            "Epoch:  110\n",
            "Loss:  132.23795497733647\n",
            "Epoch:  111\n",
            "Loss:  138.9617880136926\n",
            "Epoch:  112\n",
            "Loss:  133.15399125746822\n",
            "Epoch:  113\n",
            "Loss:  134.55662723997426\n",
            "Epoch:  114\n",
            "Loss:  166.52563529888425\n",
            "Epoch:  115\n",
            "Loss:  135.86129847293677\n",
            "Epoch:  116\n",
            "Loss:  175.15178701761286\n",
            "Epoch:  117\n",
            "Loss:  389.2303819517277\n",
            "Epoch:  118\n",
            "Loss:  149.1966378963908\n",
            "Epoch:  119\n",
            "Loss:  144.9914554095173\n",
            "Epoch:  120\n",
            "Loss:  133.2132385253831\n",
            "Epoch:  121\n",
            "Loss:  135.55237552531995\n",
            "Epoch:  122\n",
            "Loss:  134.00660992935101\n",
            "Epoch:  123\n",
            "Loss:  133.05053818032266\n",
            "Epoch:  124\n",
            "Loss:  140.92091110754066\n",
            "Epoch:  125\n",
            "Loss:  205.84475700600885\n",
            "Epoch:  126\n",
            "Loss:  173.71832014832773\n",
            "Epoch:  127\n",
            "Loss:  465.1559244871605\n",
            "Epoch:  128\n",
            "Loss:  188.83756930674198\n",
            "Epoch:  129\n",
            "Loss:  144.7671608258801\n",
            "Epoch:  130\n",
            "Loss:  150.3379271920991\n",
            "Epoch:  131\n",
            "Loss:  146.5059131870744\n",
            "Epoch:  132\n",
            "Loss:  213.18368836297728\n",
            "Epoch:  133\n",
            "Loss:  147.3402031580812\n",
            "Epoch:  134\n",
            "Loss:  151.729087500854\n",
            "Epoch:  135\n",
            "Loss:  155.59689082368945\n",
            "Epoch:  136\n",
            "Loss:  142.98409037800573\n",
            "Epoch:  137\n",
            "Loss:  180.94810767692454\n",
            "Epoch:  138\n",
            "Loss:  227.9153298949883\n",
            "Epoch:  139\n",
            "Loss:  162.86396052587722\n",
            "Epoch:  140\n",
            "Loss:  145.77058932488436\n",
            "train end\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "modelVAE=VAE(input_dim, intermediate_dim, latent_dim)\n",
        "modelVAE.fit(input=x_train[0:3], epochs=140, batch_size=None, validation_data=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(2,3, figsize = (10, 6))\n",
        "\n",
        "for i in range(len(new_test)): #Probamos con 3 imagenes del congunto de test\n",
        "    img=new_test[i][None,:]\n",
        "    out_img = modelVAE.predict(img)\n",
        "    ax[0,i].matshow(img.reshape((28,28)),  cmap='gray', clim=(0,1))\n",
        "    ax[1,i].matshow(out_img.reshape((28,28)), cmap='gray', clim=(0,1))\n",
        "pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "id": "PrexBxUcy7UQ",
        "outputId": "a650fb0a-cace-42ca-85bd-3d3d4d0acd65"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}